{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_gbwE9gMrBn7"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "zip_dir = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "base_dir = zip_dir.replace('cats_and_dogs.zip', 'cats_and_dogs_filtered')\n"
      ],
      "metadata": {
        "id": "9yYnadsWroI6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n"
      ],
      "metadata": {
        "id": "t-r6kRnkryln"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gb7EhHfEr21P",
        "outputId": "55f98366-fa21-46d1-c3b5-a097644d7e28"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "Y1hQ2z3Mr5n0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=15,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=50\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JztWv5ipr9Qo",
        "outputId": "6cac59dd-54ad-4b04-d2fb-e9775ffc39b7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "100/100 [==============================] - 142s 1s/step - loss: 0.7097 - accuracy: 0.5390 - val_loss: 0.6625 - val_accuracy: 0.6440\n",
            "Epoch 2/15\n",
            "100/100 [==============================] - 135s 1s/step - loss: 0.6497 - accuracy: 0.6250 - val_loss: 0.6554 - val_accuracy: 0.6120\n",
            "Epoch 3/15\n",
            "100/100 [==============================] - 137s 1s/step - loss: 0.5732 - accuracy: 0.7045 - val_loss: 0.6581 - val_accuracy: 0.6390\n",
            "Epoch 4/15\n",
            "100/100 [==============================] - 143s 1s/step - loss: 0.5372 - accuracy: 0.7370 - val_loss: 0.5667 - val_accuracy: 0.7090\n",
            "Epoch 5/15\n",
            "100/100 [==============================] - 151s 2s/step - loss: 0.4576 - accuracy: 0.7715 - val_loss: 0.5973 - val_accuracy: 0.7090\n",
            "Epoch 6/15\n",
            "100/100 [==============================] - 137s 1s/step - loss: 0.3750 - accuracy: 0.8310 - val_loss: 0.6610 - val_accuracy: 0.6900\n",
            "Epoch 7/15\n",
            "100/100 [==============================] - 138s 1s/step - loss: 0.2782 - accuracy: 0.8830 - val_loss: 0.7358 - val_accuracy: 0.7050\n",
            "Epoch 8/15\n",
            "100/100 [==============================] - 137s 1s/step - loss: 0.1834 - accuracy: 0.9250 - val_loss: 0.8254 - val_accuracy: 0.7050\n",
            "Epoch 9/15\n",
            "100/100 [==============================] - 136s 1s/step - loss: 0.1204 - accuracy: 0.9510 - val_loss: 1.1605 - val_accuracy: 0.7100\n",
            "Epoch 10/15\n",
            "100/100 [==============================] - 135s 1s/step - loss: 0.0915 - accuracy: 0.9670 - val_loss: 1.2613 - val_accuracy: 0.7210\n",
            "Epoch 11/15\n",
            "100/100 [==============================] - 139s 1s/step - loss: 0.0509 - accuracy: 0.9850 - val_loss: 1.6190 - val_accuracy: 0.6980\n",
            "Epoch 12/15\n",
            "100/100 [==============================] - 137s 1s/step - loss: 0.0598 - accuracy: 0.9800 - val_loss: 1.5523 - val_accuracy: 0.7010\n",
            "Epoch 13/15\n",
            "100/100 [==============================] - 137s 1s/step - loss: 0.0698 - accuracy: 0.9765 - val_loss: 1.4830 - val_accuracy: 0.6910\n",
            "Epoch 14/15\n",
            "100/100 [==============================] - 135s 1s/step - loss: 0.0484 - accuracy: 0.9850 - val_loss: 1.6184 - val_accuracy: 0.6910\n",
            "Epoch 15/15\n",
            "100/100 [==============================] - 142s 1s/step - loss: 0.0125 - accuracy: 0.9970 - val_loss: 1.8865 - val_accuracy: 0.7050\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('cats_and_dogs_model.h5')\n"
      ],
      "metadata": {
        "id": "N8VyAnbXvOj4"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}